# model
model:
  block_size: 512   # context window
  embed_dim: 512
  num_heads: 8
  num_layers: 8
  vocab_size: 8192


# train
train:
  batch_size: 8  # batch size
  lr: 3e-4
  total_steps: 20000

